## 1. TCP协议

- 其中TCP就属于传输层，并且端口号也是在传输层起作用。 

![img](https://img-blog.csdnimg.cn/3cd1fd2f36b94b76bd6cb3b2bcbf2c27.png)



TCP全称为“传输控制协议（Transmission Control Protocol）”，TCP协议是当今互联网当中使用最为广泛的传输层协议，没有之一。

TCP协议被广泛应用，其根本原因就是提供了详尽的可靠性保证，基于TCP的上层应用非常多，比如HTTP、HTTPS、FTP、SSH等，甚至MySQL底层使用的也是TCP。



### 1.1 谈谈可靠性

- 为什么网络中会存在不可靠？

  现代的计算机大部分都是基于冯诺依曼体系结构的。

![img](https://img-blog.csdnimg.cn/00a4aeedf00b48009ab63c892dea1c1e.png)

虽然这里的输入设备、输出设备、内存、CPU都在一台机器上，但这几个硬件设备是彼此独立的。如果它们之间要进行数据交互，就必须要想办法进行通信，因此这几个设备实际是用“线”连接起来的，其中连接内存和外设之间的“线”叫做IO总线，而连接内存和CPU之间的“线”叫做系统总线。由于这几个硬件设备都是在一台机器上的，因此这里传输数据的“线”是很短的，传输数据时出现错误的概率也非常低。

但如果要进行通信的各个设备相隔千里，那么连接各个设备的“线”就会变得非常长，传输数据时出现错误的概率也会大大增高，此时要保证传输到对端的数据无误，就必须引入可靠性。

总之，**网络中存在不可靠的根本原因就是，长距离数据传输所用的“线”太长了，**数据在长距离传输过程中就可能会出现各种各样的问题，而TCP就是在此背景下诞生的，TCP就是一种保证可靠性的协议。



- **思维扩展：**
  - 实际单独的一台计算机可以看作成一个小型的网络，计算机上的各种硬件设备之间实际也是在进行数据通信，并且它们在通信时也必须遵守各自的通信协议，只不过它们之间的通信协议更多是描述一些数据的含义。



- **为什么会存在UDP协议？**

TCP协议是一种可靠的传输协议，使用TCP协议能够在一定程度上保证数据传输时的可靠性，而UDP协议是一种不可靠的传输协议，那UDP协议这种不可靠的协议存在有什么意义呢？

不可靠和可靠是两个中性词，它们描述的都是协议的特点。

> - TCP协议是可靠的协议，也就意味着TCP协议需要做更多的工作来保证传输数据的可靠，并且引起不可靠的因素越多，保证可靠的成本（时间+空间）就越高。
> - 比如数据在传输过程中出现了丢包、乱序、检验和失败等，这些都是不可靠的情况。
> - 由于TCP要想办法解决数据传输不可靠的问题，因此TCP使用起来一定比UDP复杂，并且维护成本特别高。
> - UDP协议是不可靠的协议，也就意味着UDP协议不需要考虑数据传输时可能出现的问题，因此UDP无论是使用还是维护都足够简单。
> - 需要注意的是，虽然TCP复杂，但TCP的效率不一定比UDP低，TCP当中不仅有保证可靠性的机制，还有保证传输效率的各种机制。

- UDP和TCP没有谁最好，只有谁最合适，网络通信时具体采用TCP还是UDP完全取决于上层的应用场景。如果应用场景严格要求数据在传输过程中的可靠性，那么就必须采用TCP协议，如果应用场景允许数据传输出现少量丢包，那么肯定优先选择UDP协议，因为UDP协议足够简单。

---



### 1.2 TCP协议格式



- TCP协议格式如下

![img](https://img-blog.csdnimg.cn/e92f63c7a21448f4936df72cb36f5577.png)

- TCP报头当中各个字段的含义如下

> - 源/目的端口号：表示数据是从哪个进程来，到发送到对端主机上的哪个进程。
> - 32位序号/32位确认序号：分别代表TCP报文当中每个字节数据的编号以及对对方的确认，是TCP保证可靠性的重要字段。
> - 4位TCP报头长度：表示该TCP报头的长度，以4字节为单位。
> - 6位保留字段：TCP报头中暂时未使用的6个比特位。
> - 16位窗口大小：保证TCP可靠性机制和效率提升机制的重要字段。
> - 16位检验和：由发送端填充，采用CRC校验。接收端校验不通过，则认为接收到的数据有问题。（检验和包含TCP首部+TCP数据部分）
> - 16位紧急指针：标识紧急数据在报文中的偏移量，需要配合标志字段当中的URG字段统一使用。
> - 选项字段：TCP报头当中允许携带额外的选项字段，最多40字节。



- TCP报头当中的6位标志位：

> - URG：紧急指针是否有效。
> - ACK：确认序号是否有效。
> - PSH：提示接收端应用程序立刻将TCP接收缓冲区当中的数据读走。
> - RST：表示要求对方重新建立连接。我们把携带RST标识的报文称为复位报文段。
> - SYN：表示请求与对方建立连接。我们把携带SYN标识的报文称为同步报文段。
> - FIN： 通知对方，本端要关闭了。我们把携带FIN标识的报文称为结束报文段。





- 几乎任何协议都要首先解决的两个问题：a、如何分离（封装）？ b、如何交付？

  

- b **如何交付？**

   我们可以发现，其是有一个16位的目的端口。于是就可以直接根据目的端口，直接决定TCP协议在[传输层](https://so.csdn.net/so/search?q=传输层&spm=1001.2101.3001.7020)当中，如果底层收到一个数据，通过目的端口向上进行交付。

]

- a **如何分离（封装）？**

​	TCP协议的报头，采取的是标准长度：**20字节**。于是便可以收到一个TCP报文时，直接先拿出来前20个字节（拿到报头）。

 而在报头和有效载荷直接还有一个东西：选项。

![image-20240315155926318](C:\Users\。\AppData\Roaming\Typora\typora-user-images\image-20240315155926318.png)

TCP的报头是变长的，其可以在TCP中携带一些TCP通讯时相关的选项。



- 那一个携带相关选项的变长报头，如何确定其大小？

  	这就与TCP报头里的有一个数据相关了！ 

​	![image-20240315160049150](C:\Users\。\AppData\Roaming\Typora\typora-user-images\image-20240315160049150.png)

**即：**

> - 当TCP获取到一个报文后，首先读取报文的前20个字节，并从中提取出4位的首部长度，此时便获得了TCP报头的大小s i z e.
> - 如果s i z e 的值大于20字节，则需要继续从报文当中读取s i z e − 20 字节的数据，这部分数据就是TCP报头当中的选项字段。
> - 读取完TCP的基本报头和选项字段后，剩下的就是有效载荷了。

需要注意的是，TCP报头当中的4位首部长度描述的基本单位是4字节，这也恰好是报文的宽度。4为首部长度的取值范围是0000 ~ 1111，因此TCP报头最大长度为15 × 4 = 60 =60字节，因为基本报头的长度是20字节，所以报头中选项字段的长度最多是40字节。

如果TCP报头当中不携带选项字段，那么TCP报头的长度就是20字节，此时报头当中的4位首部长度的值就为20 ÷ 4 = 5 , 也就是0101。

---



- 扩展

 在此我们会发现一个问题：**TCP是没有整个报文的大小的，或者说是有效载荷的大小！而UDP很明显的是携带报文长度的！**

UDP能做到在调用recvfrom的时候，在系统层面上读到的报文就是一个独立的报文，但是TCP是做不到的，因为TCP是面向字节流的。所以原则上它无法判定报文和报文的边界，也不需要判定。因为在TCP看来，其所收到的所有数据，其只要将它的那一部分（报头）拿走，剩下的交付给上层，至于这个数据的二进制字节流当中给如何被进行解释，其都完全不关心，是应用层应该关心的。

底层中，这里所谓的报头实际上叫做：**struct tcp_hdr**。传说中的tcp报头，以及未来的所有报头，其实就是一个结构体类型（位断）。

> TCP报头是位断类型，也就是说当上层交付下来一个报文的时候，或底层读上来一个报文的时候，在内核当中对应的报头：struct tcp_hdr对象。是对象也就证明其是可以被拷贝的，所以：所谓的拼接的过程就是将，对应的不同的字段拷贝到一起。提取也就是：利用起始地址指针，对起始地址指针做类型强转，便就直接提取到了报头了。强转之后，便可以直接利用指针，指向给结构体类型（位断）里的不同字段，便可以得到4位首部长度，然后利用起始地址指针 + 4位首部长度 -> 便直接定位到了有效载荷部分。
>

---



## 2. **可靠性**



**（此处只讲到了最核心的可靠性之一）**



- **是什么原因造成的不可靠？**

​	网络中存在不可靠的根本原因就是，长距离数据传输所用的“线”太长了

​	 就如同两个人在进行聊天：一次是近距离面对面聊天，一次是一个人在楼上一个人在楼下进行聊天（喊话）。第一次小声说话也听得见，第二次大声喊也不一定听的清。从此我们可以发现，距离远近的不同，造成的聊天的成本也是不同的，远距离的聊天成本增加了（可靠性是无法保证了，容易丢包）。

当两个进行网络通讯的主机设备相差的距离很遥远，就有可能在中间设备中出现丢失，距离越长参与的中间设备。所以导致的**不可靠**，单纯的就是距离边长了。

操作系统单机内部，不谈协议，不谈TCP / IP，而一旦涉及到了网络，就需要谈到TCP / IP协议。





- **什么是真正的可靠？**

在进行网络通信时，一方发出的数据后，它不能保证该数据能够成功被对端收到，因为数据在传输过程中可能会出现各种各样的错误，只有当收到对端主机发来的响应消息后，该主机才能保证上一次发送的数据被对端可靠的收到了，这就叫做真正的可靠。![img](https://img-blog.csdnimg.cn/7280761ff3054847b3813ae04255bbfd.png)

> 图注：实线表示该数据能够被对方可靠的收到，虚线则不能保证。



但TCP要保证的是双方通信的可靠性，虽然此时主机A能够保证自己上一次发送的数据被主机B可靠的收到了，但主机B也需要保证自己发送给主机A的响应数据被主机A可靠的收到了。因此主机A在收到了主机B的响应消息后，还需要对该响应数据进行响应，但此时又需要保证主机A发送的响应数据的可靠性…，这样就陷入了一个死循环。
![img](https://img-blog.csdnimg.cn/5f278778c2f0477483b090e10c3c7e23.png)



因为只有当一端收到对方的响应消息后，才能保证自己上一次发送的数据被对端可靠的收到了，但双方通信时总会有最新的一条消息，因此无法百分之百保证可靠性。



---

- **网络中存不存在100%可靠的写协议？**

**不存在！**无论是主机A还是主机B都无法保证自己作为最新发送数据的一方，发送出去的数据是否被对方收到。所以，在宏观上：是不存在100%可靠的协议的。但是，在局部上：我们能够做到100%可靠（当发送方接收到另一方的应答时，是能够100%保证的）。

 局部可靠性本质：主机A发送出去的所有的消息，只要有匹配的应答，主机A就能够保证，其所发送出的消息主机B一定接收到了 。

TCP协议的确认应答机制，**原则：无法保证最新的报文的可靠性，但是只要一个报文收到了对应的应答，就能保证我们发出的数据对方收到了。**



所以严格意义上来说，互联网通信当中是不存在百分之百的可靠性的，因为双方通信时总有最新的一条消息得不到响应。但实际没有必要保证所有消息的可靠性，我们只要保证双方通信时发送的每一个核心数据都有对应的响应就可以了。而对于一些无关紧要的数据（比如响应数据），我们没有必要保证它的可靠性。因为对端如果没有收到这个响应数据，会判定上一次发送的报文丢失了，此时对端可以将上一次发送的数据进行重传。

![img](https://img-blog.csdnimg.cn/100a0d05f53042e697d6118f19ce18a6.png)

---







![image-20240315183300517](C:\Users\。\AppData\Roaming\Typora\typora-user-images\image-20240315183300517.png)

 如此，就会出现一个问题： 发送的顺序，不一定是接收顺序 —— 这个问题也是一个不可靠的问题（数据包乱序了）。

- **client如何确认，哪一个应答，会对应哪一个请求？**

   所以我们就需要将请求和应答一一对应上，这样客户端才能更好的确认，哪一个报文是对方接收到的。所以便有了TCP报头中的一个概念. **32位序号。**

---

### **32位序号** 与确认序号

因为一定能保护每一个报文，一定是携带了完整的报头的TCP报文，则一定有32位序号。

如果双方在进行数据通信时，只有收到了上一次发送数据的响应才能发下一个数据，那么此时双方的通信过程就是串行的，效率可想而知。

因此双方在进行网络通信时，允许一方向另一方连续发送多个报文数据，只要保证发送的每个报文都有对应的响应消息就行了，此时也就能保证这些报文被对方收到了。

![img](https://img-blog.csdnimg.cn/987a893059ed46318f0266b293387c65.png)

但在连续发送多个报文时，由于各个报文在进行网络传输时选择的路径可能是不一样的，因此这些报文到达对端主机的先后顺序也就可能和发送报文的顺序是不同的。但报文有序也是可靠性的一种，因此TCP报头中的32位序号的作用之一实际就是用来保证报文的有序性的。



![image-20240315183719358](C:\Users\。\AppData\Roaming\Typora\typora-user-images\image-20240315183719358.png)

序号代表的就是，报文在发送出去的时候，可以给它携带序号。

![img](https://img-blog.csdnimg.cn/dd0cce6372cd4232862ef84a8bae71f9.png)

当server端进行应答的时候，其一定需要填上确认信号，而确认信号其里面一般都是，他所收到的报文 +1。

> TCP报头当中的32位确认序号是告诉对端，我当前已经收到了哪些数据，你的数据下一次应该从哪里开始发。
>
> - 一方面是告诉主机A，序列号在1001之前的字节数据我已经收到了。
>
> - 另一方面是告诉主机A，下次向我发送数据时应该从序列号为1001的字节数据开始进行发送。
>
>   之后主机B对主机A发来的其他报文进行响应时，发给主机A的响应当中的32为确认序号的填法也是类似的道理。
>
>   ![img](https://img-blog.csdnimg.cn/b8de783c80a14deaaa0d3598f1f41552.png)

![img](https://img-blog.csdnimg.cn/58b5833b05f046bfb8b31a022cdba1ff.png)



 我们需要注意此处的确认序号，定义并不是确定一个序号的报文接收到（TCP没有这么定），而是：确认序号对应的数字，之前的所有的报文已经全部收到了！告诉对方，下一次发送，就从确认序号指明的序号发送。

于是，就是说即使客户端没有接收到2001，但是只要接受到了3001，根据定义序号2000的报文也接收到了。

---



- **序号和确认序号：**

  - 将请求和应答进行一一对应

  - 确认序号，表示的含义：确认序号之前的数据已经全部接收到了。

  - 允许部分确认丢失，或者不给应答。

    

  - **融汇贯通的理解：**

    > 送数据的时候，如果真的是某一个报文丢失了，是一定接收不到的，比如说是2000丢了，只收到1000和3000。再怎么处理，server的确认序号不能给3001，只能1001。就是因为概念：确认序号对应的数字，之前的所有的报文已经全部收到了！所以，由于2000没有接收到，所以并不能确认序号3001，只能应答确认序号1001。
    >



- **为什么要有两个字段数字？一个：发方是序号，应答方是确认序号，不行吗？**

  >  TCP是全双工的！任何一方，既可以收，又可以发。如果server端既想给对方确认，又想同时给对方进行发送它的消息。在正常的TCP通讯中，往往给对方发送消息，本身就是应答。所以当server端既想确认应答又想发送消息，就同时需要 **序号** 与 **确认序号** 。

​	**所以：任何通讯的一方，工作方式都是全双共的，在发送确认的时候，也可能携带新的数据。**

---

#### 按序到达

- 发序号：1000 2000 3000 -> 发确认序号：1001 3001 2001，可能是乱序的。

> 这同时也是一个很大的问题，有可能客户端发送的顺序就是其所需要的申请的顺序，而网络有必须要保证数据的按序到达。而有了序号也就不用担心了，可以根据接收到的不同的序号进行排序，以此达到报文按序到达。



- **总结：**

>  **序号和确认序号是为了支持，确认应答和按序到达 —— 序号和确认序号的作用。**

 TCP是有接收缓冲区和发送缓冲区的。

![image-20240315184851284](C:\Users\。\AppData\Roaming\Typora\typora-user-images\image-20240315184851284.png)

 所以：**TCP是传输控制协议！**

换句话说，TCP协议有接收和发送，同样的客户端和服务器都有，所以本质上讲：TCP通讯其实是，双方在进行通讯时，是发送方的发送缓冲区和接收方的接收缓冲区，以及接收方的发送缓冲区和发送方的接收缓冲区，两个缓冲区之间进行来回的拷贝（拷贝的介质是网络）。所以读取数据和发送数据，就是在对应的缓冲区里进行读写。


- **融汇贯通的理解：**

> 因为TCP有发送和接收缓冲区。所以，如果我们有Client和Server，我们便就有了两队接收和发送缓冲区。**是两对互相独立的缓冲区对，所以TCP是全双工的**。



- 32位序号的作用是，保证数据的按序到达，同时这个序号也是作为对端发送报文时填充32位确认序号的根据。
- 32位确认序号的作用是，告诉对端当前已经收到的字节数据有哪些，对端下一次发送数据时应该从哪一字节序号开始进行发送。
- 序号和确认序号是确认应答机制的数据化表示，确认应答机制就是由序号和确认序号来保证的。
- 此外，通过序号和确认序号还可以判断某个报文是否丢失。
- 工作方式都是全双共的，在发送确认的时候，也可能携带新的数据。

---



### **16位窗口大小**

![image-20240315185632411](C:\Users\。\AppData\Roaming\Typora\typora-user-images\image-20240315185632411.png)

> TCP的接收缓冲区和发送缓冲区



TCP本身是具有接收缓冲区和发送缓冲区的：

- 接收缓冲区用来暂时保存接收到的数据。
- 发送缓冲区用来暂时保存还未发送的数据。
- 这两个缓冲区都是在TCP传输层内部实现的。

![img](https://img-blog.csdnimg.cn/158452990c2b438d8a7a353b8388c673.png)

- TCP发送缓冲区当中的数据由上层应用应用层进行写入。当上层调用write/send这样的系统调用接口时，实际不是将数据直接发送到了网络当中，而是将数据从应用层拷贝到了TCP的发送缓冲区当中。

- TCP接收缓冲区当中的数据最终也是由应用层来读取的。当上层调用read/recv这样的系统调用接口时，实际也不是直接从网络当中读取数据，而是将数据从TCP的接收缓冲区拷贝到了应用层而已。

- 就好比调用read和write进行文件读写时，并不是直接从磁盘读取数据，也不是直接将数据写入到磁盘上，而对文件缓冲区进行的读写操作。

![img](https://img-blog.csdnimg.cn/62277e29944743bc9a839b9cd94d9de3.png)

当数据写入到TCP的发送缓冲区后，对应的write/send函数就可以返回了，至于发送缓冲区当中的数据具体什么时候发，怎么发等问题实际都是由TCP决定的。

我们之所以称TCP为传输层控制协议，就是因为最终数据的发送和接收方式，以及传输数据时遇到的各种问题应该如何解决，都是由TCP自己决定的，用户只需要将数据拷贝到TCP的发送缓冲区，以及从TCP的接收缓冲区当中读取数据即可。

![img](https://img-blog.csdnimg.cn/ec1cb470e3d94857813dc98da3143938.png)

需要注意的是，通信双方的TCP层都是一样的，因此通信双方的TCP层都是既有发送缓冲区又有接收缓冲区。



- 发送缓冲区和接收缓冲区的作用：

> - 数据在网络中传输时可能会出现某些错误，此时就可能要求发送端进行数据重传，因此TCP必须提供一个发送缓冲区来暂时保存发送出去的数据，以免需要进行数据重传。只有当发出去的数据被对端可靠的收到后，发送缓冲区中的这部分数据才可以被覆盖掉。
> - 接收端处理数据的速度是有限的，为了保证没来得及处理的数据不会被迫丢弃，因此TCP必须提供一个接收缓冲区来暂时保存未被处理的数据，因为数据传输是需要耗费资源的，我们不能随意丢弃正确的报文。此外，TCP的数据重排也是在接收缓冲区当中进行的。

---



如果客户端发送数据太快而导致客户端来不及接收数据，而作为TCP协议将费尽千辛万苦传送过来的报文，就因为自身来不急接收就抛弃报文。抛弃一堆数据并未出现错误的报文，这是不合理的。而所有的主机都遵守这样的规则，这无疑对网络资源是一种浪费。

 而同样的，如果一个客户端发送数据的速度太慢，服务器接收数据的速度太快，一直“嗷嗷待哺”的服务器一直等待，这也是资源的浪费。

 所以：Client发送数据，既不能太快，也不能太慢。

- **如何保证发送方发送数据，不要太快 / 太慢？**

  >  **给发送方同步自己的接收能力！**



- **接收方的接收能力，由上面决定？**

  > **接收缓冲区中剩余空间的大小！**（因为数据都是发送到接收缓冲区里面）这种策略称作为：**流量控制**。而16位窗口大小就正是接收缓冲区中剩余空间的大小。
  >
  > 我们知道网络TCP协议的网络通讯，一定是会有对应的报文，就一定会由对应的报头。



- **该报头中的16位窗口大小填的是自身的剩余空间的大小还是接收方的剩余空间的大小？**

> 不用迟疑就是自己的剩余空间的大小。

1. 对方的大小我们怎么可能知道（就是不知道大小才进行的传递）。
2. 这个报文就是发送方自身构建出来的，就是要让对方知道发送方情况的。



- 接收端在对发送端发来的数据进行响应时，就可以通过16位窗口大小告知发送端自己当前接收缓冲区剩余空间的大小，此时发送端就可以根据这个窗口大小字段来调整自己发送数据的速度。

- > 窗口大小字段越大，说明接收端接收数据的能力越强，此时发送端可以提高发送数据的速度。

- > 窗口大小字段越小，说明接收端接收数据的能力越弱，此时发送端可以减小发送数据的速度。

- > 如果窗口大小的值为0，说明接收端接收缓冲区已经被打满了，此时发送端就不应该再发送数据了。



- **理解现象：**
  - 在编写TCP套接字时，我们调用read/recv函数从套接字当中读取数据时，可能会因为套接字当中没有数据而被阻塞住，本质是因为TCP的接收缓冲区当中没有数据了，我们实际是阻塞在接收缓冲区当中了。
  - 而我们调用write/send函数往套接字中写入数据时，可能会因为套接字已经写满而被阻塞住，本质是因为TCP的发送缓冲区已经被写满了，我们实际是阻塞在发送缓冲区当中了。
  - 在生产者消费者模型当中，如果生产者生产数据时被阻塞，或消费者消费数据时被阻塞，那么一定是因为某些条件不就绪而被阻塞。
    

---



### **六个标记位**

![image-20240315191520801](C:\Users\。\AppData\Roaming\Typora\typora-user-images\image-20240315191520801.png)

这六个标志位都只占用一个比特位，为0表示假，为1表示真。

- **为什么需要多个标记位？**

  ![img](https://img-blog.csdnimg.cn/ee50e529504e4005817f8ffc960d6ece.png)



- TCP报文的种类多种多样，除了正常通信时发送的普通报文，还有建立连接时发送的请求建立连接的报文，以及断开连接时发送的断开连接的报文等等。

- 收到不同种类的报文时完美需要对应执行动作，比如正常通信的报文需要放到接收缓冲区当中等待上层应用进行读取，而建立和断开连接的报文本质不是交给用户处理的，而是需要让操作系统在TCP层执行对应的握手和挥手动作。
- 也就是说不同种类的报文对应的是不同的处理逻辑，所以我们要能够区分报文的种类。而TCP就是使用报头当中的六个标志字段来进行区分的

以作为一个面对成百上千客户端的服务器，是需要能够有效的甄别出不同客户端发出的不同的报文类型。**多个标记位本质：标记报文类型。**



- **各个标记位都是什么含义？**

**基础的三个：** （后三个，后面深入再进行讲解）



#### SYN 

> - 报文当中的SYN被设置为1，表明该报文是一个连接建立的请求报文。
> - 只有在连接建立阶段，SYN才被设置，正常通信时SYN不会被设置。

#### ACK

> - 报文当中的ACK被设置为1，表明该报文可以对收到的报文进行确认。
> - 一般除了第一个请求报文没有设置ACK以外，其余报文基本都会设置ACK，因为发送出去的数据本身就对对方发送过来的数据具有一定的确认能力，因此双方在进行数据通信时，可以顺便对对方上一次发送的数据进行响应。

#### FIN

> - 报文当中的FIN被设置为1，表明该报文是一个连接断开的请求报文。
> - 只有在断开连接阶段，FIN才被设置，正常通信时FIN不会被设置。

剩下的三个后面讲解

---



## 3. **三次握手四次挥手**



- **如何理解链接？**

> 因为有大量的Client将来可能链接Server，所以Server端一定会存在大量的连接，那么操作系统就需要对这些连接进行管理 **—— 先描述，再组织。**

> **所谓的连接：**本质其实就是内核的**一种数据结构对象**，建立连接成功的时候，就是在内存中创建对应的连接对象！再对多个连接对象进行某种数据结构上的组织。

> 一个数据结构对象进行存储，是需要花费空间的，花费时间的 —— **维护连接是有成本的**（内存 + CPU资源的花费）



### **如何理解三次握手？**

![img](https://img-blog.csdnimg.cn/d59af87184da4feb9b3438f3a2666048.png)

双方在进行建立连接的时候，它们自身的状态是会发生特定的变化的。

![img](https://img-blog.csdnimg.cn/4b90fd18087542a8895b13dee2239aa1.png)

（图的线之所以会是斜线，是因为时间，接收方的发出的时间一定早于接收方接收的时间）

- 第一次握手：客户端向服务器发送的报文当中的SYN位被设置为1，表示请求与服务器建立连接。
- 第二次握手：服务器收到客户端发来的连接请求报文后，紧接着向客户端发起连接建立请求并对客户端发来的连接请求进行响应，此时服务器向客户端发送的报文当中的SYN位和ACK位均被设置为1。
- 第三次握手：客户端收到服务器发来的报文后，得知服务器收到了自己发送的连接建立请求，并请求和自己建立连接，最后客户端再向服务器发来的报文进行响应。

需要注意的是，客户端向服务器发起的连接建立请求，是请求建立从客户端到服务器方向的通信连接，而TCP是全双工通信，因此服务器在收到客户端发来的连接建立请求后，服务器也需要向客户端发起连接建立请求，请求建立从服务器到客户端方法的通信连接。



  **注意：**三次握手对服务端和客户端都要起效。说白了就是：只要认为连接建立成功，那么客户端和服务端都要保护双方都是三次握手。





- 套接字和三次握手之间的关系
  1. 在客户端发起连接建立请求之前，服务器需要先进入LISTEN状态，此时就需要服务器调用对应listen函数。
  2. 当服务器进入LISTEN状态后，客户端就可以向服务器发起三次握手了，此时客户端对应调用的就是connect函数。
  3. 需要注意的是，connect函数不参与底层的三次握手，connect函数的作用只是发起三次握手。当connect函数返回时，要么是底层已经成功完成了三次握手连接建立成功，要么是底层三次握手失败。
  4. 如果服务器端与客户端成功完成了三次握手，此时在服务器端就会建立一个连接，但这个连接在内核的等待队列当中，服务器端需要通过调用accept函数将这个建立好的连接获取上来。
  5. 当服务器端将建立好的连接获取上来后，双方就可以通过调用read/recv函数和write/send函数进行数据交互了。





- **是不是三次握手一定要保证成功？**

> 是不能保证一定握手成功的，只能保证较大概率握手成功，因为可靠指的是连接成功之后，通讯的时候能够根据ACK保证历史数据的可靠。
>
> 而且可以从三次握手的图来看，前面两次握手是有应答的，而最后一次握手确是没有应答的，所以最后一次到底到了没无从知晓。
>
> - **三次握手不一定能够保证成功！**

**融汇贯通的理解：**

> - **Client：**发一次消息 -> 收一次消息 -> 发一次消息。
> - **Server：**收一次消息 -> 发一次消息 -> 收一次消息。
>
>  所以对于无论是客户端还是服务端，都是三次，所以：***\*三次握手对服务端和客户端都要起效。\****

> 我们需要认识到，在三次握手期间，我们根本不用担心第一次丢包 / 第二次丢包，因为它们一定会有对应的应答，所以前面两次丢包一定会有对应的反馈，客户端和服务器都能够知道，能够做出后续的策略。

> 作为客户端，在三次握手期间，其实在第三次的ACK一经发出，一瞬间就会认为自己建立连接好了，但实际上很有可能服务端压根就没有收到这个ACK。



- **为什么要三次握手？一次？两次？四次？不行吗？**



- **如果是一次握手：**

>   即，客户端认为只要简单粗暴的发送一次SYN就建立好了连接，那如果客户端向服务端发送大量的SYN呢？

>  **服务器维护连接是有成本的**（内存 + CPU资源的花费），换句话说就是一个黑客，用一台电脑就简单的向服务器发送大量的SYN，就会导致一瞬间就将服务器的可用资源用完了，所以一次握手是不行的。

> 这种利用发送大量的SYN，来大量消耗服务端资源的情况，叫做：***\*SYN洪水\****。（这样的连接充满了明显漏洞）

- **如果是两次握手：**

>   即，客户端向服务端发送了一个SYN，服务端再直接向客户端发送SYN+ ACK，然后连接建立好了。服务端认为连接好了，是只要第二个报文发出后就认为了。服务器无法保证自己第二次握手的时候，自己发出的SYN+ ACK被客户端收到。

>  如果一个客户端大量的发送SYN，并且其知道一定会收到ACK，但是不用就是直接丢弃，然后就无脑发送SYN，于是服务器照样被灌满大量链接。（这样的连接充满了明显漏洞）

- **三次握手：**

> 当客户端发送最后一次ACK的时候，是只要客户端把ACK发出了，客户端就认为连接建立好了。而对于服务器来讲，其必须要收到这个最后的ACK保证三次握手完成，才认为建立连接成功。

>  换句话说：服务器建立连接成功的时间点，相对于客户端建立连接成功的时间点要延后那么一点点。也就是说让服务器维护连接时，客户端一定也要维护起连接 —— 客户端可以，以发大量请求攻击服务器，但是要是进行了攻击，服务器所承受的连接，客户端一定也要承受等价的连接。

>  以此达到防止单机的情况下无法对服务器发起攻击，因为服务器的配置比客户端的配置大太多了。

**融汇贯通的理解：**

> 最后一次ACK服务端并未接收到，客户端却认为连接建立成功了，这个时候，成本是嫁接到客户端的
>
>     所以，三次握手就是以最小的成本，让连接在建立的时候，不会过度的去消耗服务端的资源。
>     
>     但是，实际上TCP的三次握手，TCP在需要保证连接安全这个问题，并不是简简单单的靠三次握手就能够解决的（本身也不是为了安全问题而设计的，只是顺带的罢了）。

>   但是，架不住有黑客有很多的机器，比如说：其利用木马病毒入侵用户端口，然后木马病毒在入侵的笔记本后端，开了一个端口，然后这个端口可以接收来自黑客的指令（以此控制了上万台电脑）。然后拿着上万台机器的ip地址 / 其他信息，然后在一个时间点向所有主机发送请求，请求内容是向一个网站发送请求，这样也可以将服务器搞崩。
>
> 所以其会有很多安全得到处理方式，比如说甄别非法请求等，像如一个客户端在短时间内发送大量的请求，于是这个客户端的ip立马加进黑名单。而如公司内网的机器，就可以直接添加进入白名单。

- **为什么是三次握手：**
  1. 是双方在建立共识的过程。
  2. server可以嫁接同等的成本给client —— 在不考虑恶意用户的情况下，确保了服务器的安全。
  3. 验证全双工 —— 保证任何客户端与服务端都要能收又能发。

 

- **四次握手？**

>  三次握手已经够了，完全没有必要浪费资源进行继续握手。

---

#### **RST**

（（reset）连接重置）

   如果客户端发送ACK后服务端没有收到，但是客户端认为连接是建立成功的，于是直接发送数据呢？服务端就发现连接都没建立成功，却直接发送报文，甚至还带上数据，于是便出现：连接认知不一致的情况。于是服务端认识到，客户端连接建立出现了问题，所以服务器立马就回复一个报文（就是TCP报头），并且将RST（reset）标记位：连接重置，标识上，然后让客户端认识到，这个连接建立是由问题的，不能进行通讯。

 于是客户端直接将这个连接关闭，然后再重新向服务端发起三次握手。所以**RST表征：**连接建立的过程之中（之后），双方通讯过程之中有可能连接出现了异常，而导致对方可能不知情而继续发消息时，需要关闭对方的连接，让对方重新建立连接的报文。

这个概率时非常低的，实际上其也并不会存在，因为实际上：其实如果客户端再立马发送的报文内部，ACK是置1的，所以其实ACK也有，连接是会建立成功的。但是在某些情况下，如：Server出现异常连接断了，这个时候RST的意义的凸显出来了（如：我们访问一个网站的时候，如果我们长时间不使用，再使用的时候，就有可能出现提示：连接中断需要重置的提示）。


---

#### PSH

- 报文当中的PSH被设置为1，是在告诉对方尽快将你的接收缓冲区当中的数据交付给上层。

 已经将连接建立好了，然而在一次客户端发送报文数据后，服务器回复ACK并且16位窗口大小为0了，然后客户端就只能等待客户端那边有空间。于是一直等，甚至是等 "急了" ，客户端发送了一个不带任何有效数据的报文，让服务端回复，以查看16位窗口大小，但是发现还是0。于是长时间等待客户端就发送了一个PSH（push）标记位：督促对方尽快将数据向上交付。

以此让客户端知道服务端等了很久，于是尽快的将数据进行向上交付。



- 还有一种情况

我们一般认为：

- 当使用read/recv从缓冲区当中读取数据时，如果缓冲区当中有数据read/recv函数就能够读到数据进行返回，而如果缓冲区当中没有数据，那么此时read/recv函数就会阻塞住，直到当缓冲区当中有数据时才会读取到数据进行返回。

实际这种说法是不太准确的，其实接收缓冲区和发送缓冲区都有一个水位线的概念。

![img](https://img-blog.csdnimg.cn/36298a1a6a5c4f2d888582d0e8f87aaf.png)

- 比如我们假设TCP接收缓冲区的水位线是100字节，那么只有当接收缓冲区当中有100字节时才让read/recv函数读取这100字节的数据进行返回。

- 如果接收缓冲区当中有一点数据就让read/recv函数读取返回了，此时read/recv就会频繁的进行读取和返回，进而影响读取数据的效率（在内核态和用户态之间切换也是有成本的）。

- 因此不是说接收缓冲区当中只要有数据，调用read/recv函数时就能读取到数据进行返回，而是当缓冲区当中的数据量达到一定量时才能进行读取。

当报文当中的PSH被设置为1时，实际就是在告知对方操作系统，尽快将接收缓冲区当中的数据交付给上层，尽管接收缓冲区当中的数据还没到达所指定的水位线。这也就是为什么我们使用read/recv函数读取数据时，期望读取的字节数和实际读取的字节数是不一定吻合的。

---

#### URG

（（urge）紧急标记位，需要配合16位紧急指针进行使用）

之前提到过一个概念：按序到达。所以就是因为TCP是按序到达的机制，这是TCP的优点，而有优点就会有对应的缺点：因为我们发送的报文，被对方上层读到的时候，必须具有先后顺序。



- 万一有时候TCP想将对应的报文插队交付（尽快将一个报文进行交付）呢？

> 于是，便有了URG（urge）标记位：紧急标记位，需要配合16位紧急指针进行使用。



##### **16位紧急指针**

![image-20240315200413440](C:\Users\。\AppData\Roaming\Typora\typora-user-images\image-20240315200413440.png)

一般报文的**16位紧急标记位**都是被清0的，代表其就必须按照常规的排队队列，依次向上进行交付，但是如果设置了**16位紧急指针**，那么上层可以通过特定的读取选项，来高优先级的将这部分**16位紧急指针**，所指向的有效载荷部分的数据，尽快向上层交付。

  URG标记位代表16位紧急指针是否有效。



- 但是还是有一个问题：这里只是知道了，紧急数据的偏移量，也就是起始的位置，但是紧急数据有多少呢？

> 不用想了，就一个字节。只有**16位紧急指针**偏移量所指向的***\*一个字节\****能够被称作为紧急数据。



- **那这么做有什么目的？**

  当一个服务器可能由于请求过多或申请过多导致 "卡住" 不动，于是有一个客户端发现，连接时保持着的，但是服务器又总是不给其任何反应，于是客户端想知道服务器到底出现了什么问题，是什么情况。而有一些机器上也是部署的有一些服务（基于TCP），如果机器卡住不动了，客户端可以通过16位紧急数据，向服务器发起询问。

于是由于这个数据不进行排队，然后就会优先级更高的直接向上递交，然后询问服务器主机现在处于的状态。所以**16位紧急指针**通常是用来作机器管理的命令，其不走正常通讯的数据流程。



recv函数的第四个参数flags有一个叫做MSG_OOB的选项可供设置，其中OOB是带外数据（out-of-band）的简称，带外数据就是一些比较重要的数据，因此上层如果想读取紧急数据，就可以在使用recv函数进行读取，并设置MSG_OOB选项。

![img](https://img-blog.csdnimg.cn/379cf71c1bcc45dca273f3738c1cf054.png)

与之对应的send函数的第四个参数flags也提供了一个叫做MSG_OOB的选项，上层如果想发送紧急数据，就可以使用send函数进行写入，并设置MSG_OOB选项.

![img](https://img-blog.csdnimg.cn/d5f6bb9b6bfd48f39dc8b9c7dbb62dcf.png)

---



### 如何理解四次挥手？

- 首先对于连接，肯定是需要一方主动的，而断开连接：
  1. 双方都有可能优先断开连接。
  2. 断开连接是两边共同的事情，需要挣得两方的同意。

![img](https://img-blog.csdnimg.cn/ce265e000e0c4d048cdc45801ef8cead.png)

也有可能客户端断开连接的时候，服务端也向断开连接，于是很有可能4次挥手中的2、3次挥手合为一次握手，变为3次握手（本身应答标记位ACK与断开连接标记位FIN就不是一个位置上的，所以完全可以一起执行）



- **断开连接就一定成功吗？**

  > 与连接的三次握手一样的，也不能保证一定断开成功。但是也没有问题，无非就是一个认为断开，一个认为连接，然后连接的那个长时间的不访问，于是就闲置时间久了自动的断开了。



**四次挥手对应的状态变化：**

![img](https://img-blog.csdnimg.cn/e87a1423a28346ac9438579f9743281f.png)

- 第一次挥手：客户端向服务器发送的报文当中的FIN位被设置为1，表示请求与服务器断开连接。
- 第二次挥手：服务器收到客户端发来的断开连接请求后对其进行响应。

- 第三次挥手：服务器收到客户端断开连接的请求，且已经没有数据需要发送给客户端的时候，服务器就会向客户端发起断开连接请求。
- 第四次挥手：客户端收到服务器发来的断开连接请求后对其进行响应。

四次挥手结束后双方的连接才算真正断开。



- 为什么是四次挥手？

> - 由于TCP是全双工的，建立连接的时候需要建立双方的连接，断开连接时也同样如此。在断开连接时不仅要断开从客户端到服务器方向的通信信道，也要断开从服务器到客户端的通信信道，其中每两次挥手对应就是关闭一个方向的通信信道，因此断开连接时需要进行四次挥手。

> - 需要注意的是，四次挥手当中的第二次和第三次挥手不能合并在一起，因为第三次握手是服务器端想要与客户端断开连接时发给客户端的请求，而当服务器收到客户端断开连接的请求并响应后，服务器不一定会马上发起第三次挥手，因为服务器可能还有某些数据要发送给客户端，只有当服务器端将这些数据发送完后才会向客户端发起第三次挥手。



- 四次挥手时的状态变化如下：

1. 在挥手前客户端和服务器都处于连接建立后的ESTABLISHED状态。
2. 客户端为了与服务器断开连接主动向服务器发起连接断开请求，此时客户端的状态变为FIN_WAIT_1。
3. 服务器收到客户端发来的连接断开请求后对其进行响应，此时服务器的状态变为CLOSE_WAIT。
4. 当服务器没有数据需要发送给客户端的时，服务器会向客户端发起断开连接请求，等待最后一个ACK到来，此时服务器的状态变为LASE_ACK。
5. 客户端收到服务器发来的第三次挥手后，会向服务器发送最后一个响应报文，此时客户端进入TIME_WAIT状态。
6. 当服务器收到客户端发来的最后一个响应报文时，服务器会彻底关闭连接，变为CLOSED状态。
7. 而客户端则会等待一个2MSL（Maximum Segment Lifetime，报文最大生存时间）才会进入CLOSED状态。

至此四次挥手结束，通信双方成功断开连接。



- 套接字和四次挥手之间的关系

> - 客户端发起断开连接请求，对应就是客户端主动调用close函数。
> - 服务器发起断开连接请求，对应就是服务器主动调用close函数。
> - 一个close对应的就是两次挥手，双方都要调用close，因此就是四次挥手。



---

- **CLOSE_WAIT：**

> ​    我们知道当一个连接发送FIN的时候，对应的就是上层调用了close。

- **如果我们发现服务器具有大量的CLOSE_WAIT状态的连接的时候，原因是什么？**

>   说明操作系统的状态没有向后走，就是因为服务器没有发送FIN，就是因为应用层服务器写的有bug，我们忘了关闭对应的连接sockfd。

**融汇贯通的理解：**

>  在编码层面上，不关会导致文件描述符泄漏的问题（可用的文件描述符越来越小）。二文件描述符就是一个代表，其底层操作系统为了维护其所匹配的资源，要为其创建大量的数据结构。
>
> 所以使用netstat查的时候，出现了大量的**CLOSE_WAIT**状态，一定是上层忘了关闭对应的连接，所以未来服务器如果运行的越来越卡，服务器周期性的过一段时间就卡死了，就一定要使用netstat查一下，看一下是不是我们的服务器上面是不是挂满了CLOSE_WAIT状态，是不是因为代码的有一些的细节导致文件描述符没有关闭
>



- **TIME_WAIT：**

> 这里也是解决我们前面日常学习中：我们所写的测试服务端，在使用一个端口号开启一个服务端后，终止服务端再使用该端口启动服务端，却无法启动的问题所在。

> 文件描述符的生命周期是随进程的，我们将服务端关闭，也就是将进程关闭，于是自动close文件描述符，于是在四次挥手中就是服务端关闭先断开的连接，最后客户端需要进入TIME_WAIT状态等待一段时间后，才会发送ACK给服务端然后CLOSED。而我们立马使用原端口启动服务器，正好其还处于TIME_WAIT状态，于是无法bind。
>

>  **核心：**主动断开的一方需要维持等待状态**TIME_WAIT**状态（虽然四次挥手已经完成），在该状态下，连接其实已经解开，但是地址信息ip、port依旧是被占用着。

> 等待时间受：操作系统TCP协议自身的设置 + 用户配置的设置。

- **这会带来什么影响？**

>   再日常生活中，比如双11、618等购物节日，像淘宝、拼多多、京东这样的大型网上交易软件，当在这个种消费节日下，如果由于过多的用户访问，出现过多的连接导致服务器撑不住，崩溃了，于是最好的情况肯定是立马重启，但是很尴尬的就是，由于服务器崩溃，于是边成为了主动断开连接的一方，那么最后就需要等待。大量的连接保持TIME_WAIT状态，难道等好几分钟让其进入CLOSED？
>

> 很明显这是不可能的，像这种大型app，交易高峰几秒内交易上千万完全是可能的。这样的等待无疑是巨大的损失。于是**我们就要保证一个服务器挂掉，要有立马能够重启的能力。**

> 系统就提供了一个接口，这个接口是当我们在创建listen套接字的时候，需要设置一下listen套接字的属性：***\*socksetopt\****

----

#### socksetopt

设置套接字的属性。

![img](https://img-blog.csdnimg.cn/07d407ddc88849deb9114b984f45f679.png)

```c++
#include <sys/types.h>
#include <sys/socket.h>
 
int setsockopt(int sockfd, int level, int optname, const void *optval, socklen_t optlen);
```

**参数：**

  **sockfd：**是套接字描述符。

   **level：**是被设置的选项的级别，如果想要在套接字级别上设置选项，就必须把level设置为 ***\*SOL_SOCKET\****。

  **option_name：**指定准备设置的选项，option_name可以有哪些取值，这取决于level。在套接字级别上(SOL_SOCKET)：  

> SO_REUSEADDR：打开或关闭地址复用功能。当option_value不等于0时，打开，否则，关闭。它实际所做的工作是置sock->sk->sk_reuse为1或0。

 **optval：**指向在其中指定所请求选项值的缓冲区的指针。

 **optlen：**optval 参数指向的缓冲区的大小（以字节为单位）。



 这个时候如果我们的服务器挂掉，我们的服务区的可以绕过**TIME_WAIT**状态的判断，而直接让我们的服务器绑定成功。

![img](https://img-blog.csdnimg.cn/45e583c88f3245da83a7e4593e06e45b.png)

 opt表示一个标记位要打开。 

 这个时候因为我们设置了地址复用，让我们对应的端口号和IP地址可以在**TIME_WAIT**状态期间被我们的服务立马绑定。



- **为什么要有TIME_WAIT状态？**

> 首先在我们正常的做网路通讯的时候，当双方在协商断开连接的时候，可能历史连接通讯的时候，网络当中可能会存在一些报文滞留在网络当中。还没有送达客户端或者服务器，所以维持一个**TIME_WAIT**状态，让还在路上的报文到达（**TIME_WAIT**状态等待的时间，在网络中至少是2倍MSL）。

MSL在RFC1122中规定为两分钟，但是各个操作系统的实现不同，比如在Centos7上默认配置的值是60s。我们可以通过`cat /proc/sys/net/ipv4/tcp_fin_timeout`命令来查看MSL的值。

![img](https://img-blog.csdnimg.cn/766a1df9f40d495eb96154acc3d69c26.png)

> **MSL**(Max Segment Life，报文最大生存时间)**：**
>
> ​    两个主机网络通讯，从一个到另一个的单向上数据到达对方时，所花费的最大时间。

 依次保证历史数据从网络中进行消散。

> **消散：**要么被双方所接收，要么被对方所丢弃。



- **为什么要消散？**

>  主要原因是，因为一个客户端和服务器，断开连接之后，还有可能很快的重新建立连接，甚至用的端口号，源端口、目的端口、原IP、目的IP都是可能一样的。这就很尴尬了，这些报文就会影响客户端和服务器之间的正常通讯。所以尽量的需要保证网络中的数据进行消散。



 对于此（TIME_WAIT状态等待的时间，在网络中至少是2倍MSL），还有一个更好的理解：毕竟我们要四次挥手才算正式断开，如果是客户端断开连接，而最后一次ACK发送失败了，客户端认为断开了，而服务器却没有收到。如果不等待直接进入CLOSED，于是没有收到的客户端就会重传FIN再继续问，但是客户端已经关闭了，于是发送一点用处也没有。于是导致服务器一直没有办法关闭，导致一些问题。

 所以让客户端进入**TIME_WAIT**状态等待一段时间的好处就是，如果ACK丢了，对方重传的FIN客户端也可以收到，然后补发ACK。如果有出现了其他情况，导致等待时间过了也没有解决，也问题不大服务器在特定时间段内也会自动关闭。



 **TIME_WAIT**状态等待课较大的提高ACK的发送成功的概率。

---



## 4. **可靠性机制**

- > TCP保证可靠性的机制之一就是确认应答机制。



### **确认应答(ACK)机制**

![img](https://img-blog.csdnimg.cn/424f7f65efc744f79d74f8af5ff83875.png)

确认应答机制就是由TCP报头当中的，32位序号和32位确认序号来保证的。需要再次强调的是，确认应答机制不是保证双方通信的全部消息的可靠性，而是通过收到对方的应答消息，来保证自己曾经发送给对方的某一条消息被对方可靠的收到了。



-    在TCP层，我们一般把所有发出去的数据 / 报文，通常统一叫做数据段，数据段 = 报头 + 有效载荷数据



- **缓冲区与序号的理解**

>  TCP在发送数据时，是有发送缓冲区的，在接收数据时，也是有接收缓冲区的。同样的对方的主机也具有发送缓冲区和接收缓冲区。



- **以客户端向服务器发送数据为例：**

  TCP自带了一个发送缓冲区（可以想象为一个字符类型的数组），于是忽对于TCP，上层需要其发送给数据，就依次的拷贝入 "char类型的数组" ，这样每一个字节天然的就有了一个序号，这个序号就是对应的数组下标。

![image-20240316191232777](C:\Users\。\AppData\Roaming\Typora\typora-user-images\image-20240316191232777.png)

 当发送数据的时候，如一个 0~1000 的数据，则这一个报文的编号就是以最后一个下标 1000 为编号，然后构建一个序号给对方发出，下一次 1001~2023 的序号就编号为2023。然后对方再以序号的方式接收，并且组合，接收方就能够也将其当作字符类型的数组，收的时候就能够按照特定的顺序，将数据拷贝到自己的接收缓冲区里，然后交付给上层。

 TCP将每个字节的数据都进行了编号，即为序列号：

![img](https://img-blog.csdnimg.cn/d8593287e1454d85984ae04977360517.png)

 每一个ACK都带有对应的确认序列号，确认信号是对序号 +1，意思是告诉发送者，我已经收到了哪些数据，下一次你从哪里开始发。 



- **融汇贯通的理解：**

> 这里也能够大概看出来，TCP面向字节流的概念。因为将其当作为char类型的数组，所以char类型数组大小一个一个就是字节，所以将这种双方都用char类型 / 字节流方式保存的放在缓冲区的数据，叫做**面向字节流**。



---

### **超时重传机制**

双方在进行网络通信时，发送方发出去的数据在一个特定的事件间隔内如果得不到对方的应答，此时发送方就会进行数据重发，这就是TCP的超时重传机制。

![img](https://img-blog.csdnimg.cn/97d1739edc564d2e8e689390f98a91e6.png)

- 主机A发送数据给B之后，可能因为网络拥堵等原因，数据无法到达主机B。

- 如果主机A在一个特定时间间隔内没有收到B发来的确认应答，就会进行重发。

  

  丢包的另一种情况其实不是发送端发送的数据丢包了，而是对方发来的响应报文丢包了，此时发送端也会因为收不到对应的响应报文，而进行超时重传。

![img](https://img-blog.csdnimg.cn/aacac01f9b974d41b007af5a1cd16bdb.png)

- 当出现丢包时，发送方是无法辨别是发送的数据报文丢失了，还是对方发来的响应报文丢失了，因为这两种情况下发送方都收不到对方发来的响应报文，此时发送方就只能进行超时重传。

- 如果是对方的响应报文丢失而导致发送方进行超时重传，此时接收方就会再次收到一个重复的报文数据。那么 TCP 协议需要能够识别出那些包是重复的包 ， 并且把重复的丢弃掉。 这时候就是利用前面提到的序列号， 就可以很容易做到去重的效果。

- 需要注意的是，当发送缓冲区当中的数据被发送出去后，操作系统不会立即将该数据从发送缓冲区当中删除或覆盖，而会让其保留在发送缓冲区当中，以免需要进行超时重传，直到收到该数据的响应报文后，发送缓冲区中的这部分数据才可以被删除或覆盖。





- **那么超时的时间如何确定?**

  超时重传的时间不能设置的太长也不能设置的太短

> **时间太长：**早就超时了，还在等待导致效率太低。
>
> **时间太短：**超时重传的时间设置的太短，会导致对方收到大量的重复报文，可能对方发送的响应报文还在网络中传输而并没有丢包，但此时发送方就开始进行数据重传了，并且发送大量重复报文会也是对网络资源的浪费。

> 因此超时重传的时间一定要是合理的，最理想的情况就是找到一个最小的时间，保证“确认应答一定能在这个时间内返回”。但这个时间的长短，是与网络环境有关的。网好的时候重传的时间可以设置的短一点，网卡的时候重传的时间可以设置的长一点，也就是说超时重传设置的等待时间一定是上下浮动的，因此这个时间不可能是固定的某个值。
>



- **超时重传的策略重点：**

1. 最理想的情况下，找到一个最小的单元时间，保证 "确认应答一定能在这个时间内返回"。
2. 但是这个时间的长短，随着网络环境的不同，是有差异的。
3. 如果超时时间设的太长，会影响整体的重传效率。
4. 如果超时时间设的太短，有可能会频繁发送重复的包。 

- **TCP 为了保证无论在任何环境下都能比较高性能的通信 ， 因此会动态计算这个最大超时时间。**

1. Linux中（BSD Unix和Windows也是如此），超时以500ms为一个单位进行控制，每次判定超时重发的超时时间都是500ms的整数倍。
2. 如果重发一次之后，仍然得不到应答，下一次重传的等待时间就是2 × 500 ms
3. 如果仍然得不到应答，等待 4*500ms 进行重传。依次类推，以指数形式递增。
4. 累计到一定的重传次数，TCP认为网络或者对端主机出现异常，TCP强制关闭连接。

---



### **连接管理机制**

在正常情况下，TCP要经过三次握手建立连接，四次挥手断开连接。

![img](https://img-blog.csdnimg.cn/db6204e1ff2d4c878e7436bee224145d.png)

**（上面已经讲解了对应的三次握手建立连接，四次挥手断开连接，所以此处就总结一下客户端和服务端中的状态转换）**



**服务端状态转化：**

-  [CLOSED -> LISTEN] 服务器端调用listen后进入LISTEN状态，等待客户端连接。
- [LISTEN -> SYN_RCVD] 一旦监听到连接请求(同步报文段)，就将该连接放入内核等待队列中，并向客户端发送SYN确认报文。
- [SYN_RCVD -> ESTABLISHED] 服务端一旦收到客户端的确认报文 ， 就进入 ESTABLISHED 状态 ， 可以进行读写数据了。
- [ESTABLISHED -> CLOSE_WAIT] 当客户端主动关闭连接 ( 调用 close)， 服务器会收到结束报文段 ， 服务器返回确认报文段并进入CLOSE_WAIT。
- [CLOSE_WAIT -> LAST_ACK] 进入 CLOSE_WAIT 后说明服务器准备关闭连接 ( 需要处理完之前的数据 )。 当服务器真正调用close 关闭连接时 ， 会向客户端发送 FIN， 此时服务器进入 LAST_ACK 状态 ， 等待最后一个ACK到来 ( 这个 ACK 是客户端确认收到了 FIN)
- [LAST_ACK -> CLOSED] 服务器收到了对 FIN 的 ACK， 彻底关闭连接



**客户端状态转化：**

- [CLOSED -> SYN_SENT] 客户端调用connect，发送同步报文段。
- [SYN_SENT -> ESTABLISHED] connect调用成功，则进入ESTABLISHED状态，开始读写数据。
- [ESTABLISHED -> FIN_WAIT_1] 客户端主动调用close时，向服务器发送结束报文段，同时进入 FIN_WAIT_1

- [FIN_WAIT_1 -> FIN_WAIT_2] 客户端收到服务器对结束报文段的确认，则进入FIN_WAIT_2， 开始等待服务器的结束报文段。

- [FIN_WAIT_2 -> TIME_WAIT] 客户端收到服务器发来的结束报文段，进入TIME_WAIT，并发出LAST_ACK。

- [TIME_WAIT -> CLOSED] 客户端要等待一个2MSL(Max Segment Life, 报文最大生存时间)的时间，才会进入CLOSED状态。

  

**下图是TCP状态转换的一个汇总：**

![img](https://img-blog.csdnimg.cn/59eb3dde5e4a488f8b57bdd579b3bead.png)

- 较粗的虚线表示服务端的状态变化情况。
- 较粗的实线表示客户端的状态变化情况。
- CLOSED是一个假想的起始点，不是真实状态。

---



**再对TIME_WAIT总结：**

- TCP协议规定，主动关闭连接的一方要处于TIME_ WAIT状态，等待两个MSL(maximum segment lifetime)的时间后才能回到CLOSED状态。
- 我们使用Ctrl-C终止了server，所以server是主动关闭连接的一方，在TIME_WAIT期间仍然不能再次监听同样的server端口。

可以通过在listen的时候设置函数socksetopt，使得对应的端口号和IP地址可以在**TIME_WAIT**状态期间被我们的服务立马绑定。![img](https://img-blog.csdnimg.cn/45e583c88f3245da83a7e4593e06e45b.png)



- **TIME_WAIT状态的保持会带来的问题？**

  > 在server的TCP连接没有完全断开之前不允许重新监听, 某些情况下可能是不合理的：

> - 服务器需要处理非常大量的客户端的连接（每个连接的生存时间可能很短，但是每秒都有很大数量的客户端来请求）。
> - 这个时候如果由服务器端主动关闭连接（比如某些客户端不活跃，就需要被服务器端主动清理掉），就会产生大量TIME_WAIT连接。
> - 由于我们的请求量很大，就可能导致TIME_WAIT的连接数很多，每个连接都会占用一个通信五元组（源ip，源端口，目的ip，目的端口，协议）。其中服务器的ip和端口和协议是固定的，如果新来的客户端连接的ip和端口号和TIME_WAIT占用的链接重复了，就会出现问题。



- **为什么是TIME_WAIT的时间是2\*MSL?**

> 1. MSL是TCP报文的最大生存时间，因此TIME_WAIT持续存在2MSL的话就能保证在两个传输方向上的尚未被接收或迟到的报文段都已经消失（否则服务器立刻重启，可能会收到来自上一个进程的迟到的数据，但是这种数据很可能是错误的）。
> 2. 同时也是在理论上保证最后一个报文可靠到达（假设最后一个ACK丢失，那么服务器会再重发一个FIN。这时虽然客户端的进程不在了，但是TCP连接还在，仍然可以重发LAST_ACK）。

---



## 5. **三大机制**

- 流量控制
- 拥塞控制
- 滑动窗口

---

### **流量控制**

 接收端处理数据的速度是有限的。 如果发送端发的太快 ， 导致接收端的缓冲区被打满 ， 这个时候如果发送端继续发送， 就会造成丢包， 继而引起丢包重传等等一系列连锁反应 。

因此TCP 支持根据接收端的处理能力 , 来决定发送端的发送速度 。 这个机制就叫做 **流量控制** **(Flow Control)。**

- 接收端将自己可以接收的缓冲区大小放入 TCP 首部中的 "窗口大小" 字段，***\*通过\**\**ACK\******端通知发送端**
- 窗口大小字段越大，说明网络的吞吐量越高。
- 接收端一旦发现自己的缓冲区快满了，就会将窗口大小设置成一个更小的值通知给发送端。
- 发送端接受到这个窗口之后，就会减慢自己的发送速度。
- 如果接收端缓冲区满了，就会将窗口置为0。这时发送方不再发送数据，但是需要定期发送一个窗口探测数据段，使接收端把窗口大小告诉发送端。



当发送端得知接收端接收数据的能力为0时会停止发送数据，此时发送端会通过以下两种方式来得知何时可以继续发送数据。

- 等待告知。接收端上层将接收缓冲区当中的数据读走后，接收端向发送端发送一个TCP报文，主动将自己的窗口大小告知发送端，发送端得知接收端的接收缓冲区有空间后就可以继续发送数据了。
- 主动询问。发送端每隔一段时间向接收端发送报文，该报文不携带有效数据，只是为了询问发送端的窗口大小，直到接收端的接收缓冲区有空间后发送端就可以继续发送数据了。

![img](https://img-blog.csdnimg.cn/1663f62fea6a415d91c7e0b2e246a438.png)



- **融汇贯通的理解：**

  >   每一个主机上都有接收和发送缓冲区。客户端和服务端的：
  >
  > - - 客户端发送缓冲区 - 服务端接收缓冲区
  >   - 服务端发送缓冲区 - 客户端接收缓冲区
  >
  > 是一一对应的两队，所以TCP是全双工的（对应的发送缓冲区的数据拷贝到接收缓冲区），而这样相互客户端ACK服务端，服务端ACK客户端，就是通告互相各自剩余接收缓冲区大小 —— **流量控制**

  

-  **接收端如何把窗口大小告诉发送端呢?**

>  回忆我们的TCP 首部中的学习，讲解到的 有一个 16 位窗口字段 ， 就是存放了窗口大小信息。
>
> ![image-20240316195532814](C:\Users\。\AppData\Roaming\Typora\typora-user-images\image-20240316195532814.png)



- **第一次向对方发送数据时如何得知对方的窗口大小？**

> 双方在进行TCP通信之前需要先进行三次握手建立连接，而双方在握手时除了验证双方通信信道是否通畅以外，还进行了其他信息的交互，其中就包括告知对方自己的接收能力，因此在双方还没有正式开始通信之前就已经知道了对方接收数据能力，所以双方在发送数据时是不会出现缓冲区溢出的问题的。
>
> 客户端也会过一段时间就询问服务端是否有空间。并且光有这一种策略还不够完整，还有一种策略是，如果主机B的窗口更新了，其也直接会向主机A发送窗口更新的通知，这两种策略同时进行。进而就是看是探测先来还是更新先来。



- **16为数字最大表示65535，那TCP窗口最大就是65535吗？**

> 理论上确实是这样的，但实际上TCP报头当中40字节的选项字段中包含了一个窗口扩大因子M，实际窗口大小是窗口字段的值左移M位得到的。



---



### **滑动窗口**

  是一个主要为了提高TCP网络效率的机制。



在之前我们已经讨论了确认应答策略，对每一个发送的数据段，都要给一个ACK确认应答（严格的确认应答机制）。收到ACK后再发送下一个数据段，这样做有一个比较大的缺点，就是性能较差，尤其是数据往返的时间较长的时候。

所有的发送过程都是串行的，既一个一个的发送，没有错，但是效率低下。既然这样一发一收的方式性能较低.

双方在进行TCP通信时可以一次向对方发送多条数据，这样可以将等待多个响应的时间重叠起来，进而提高数据通信的效率。

![img](https://img-blog.csdnimg.cn/6a8c070ad0bd49b180eef8213e26cd01.png)

 发出方一批次的发送，接收方再一批次的应答，这样发出的一批次的报文，是在网络中并行的同时过去的，确认也是并行的同时过来。这样多个IO的时间是重叠到一起的，那么这就能够提高对应的效率。



- **并行的发送了一大批的数据段需要每一个都要有应答吗？** 

​	 理论上是每一个发出的**数据段**都必须要有对应的应答。

![img](https://img-blog.csdnimg.cn/c5487acdc74f4017ae05babb3ea9e2d7.png)

其实可以将发送缓冲区当中的数据分为三部分：

- 已经发送并且已经收到ACK的数据。
- 已经发送还但没有收到ACK的数据。
- 还没有发送的数据。

这里发送缓冲区的第二部分就叫做滑动窗口。（也有人把这三部分整体称之为滑动窗口，而将其中的第二部分称之为窗口大小）

 **滑动窗口：**在自己的发送缓冲区中，属于自己的发送缓冲区的一部分。

![img](https://img-blog.csdnimg.cn/7d29c1931ffd41a7910d289e9b1b6a4a.png)

而滑动窗口描述的就是，发送方不用等待ACK一次所能发送的数据最大量。

![img](https://img-blog.csdnimg.cn/258d8d20ab1547a0888aaebbe85adad2.png)



- 滑动窗口存在的最大意义就是可以提高发送数据的效率：
  - 滑动窗口的大小等于对方窗口大小与自身拥塞窗口大小的较小值，因为发送数据时不仅要考虑对方的接收能力，还要考虑当前网络的状况。
  - 我们这里先不考虑拥塞窗口，并且假设对方的窗口大小一直固定为4000，此时发送方不用等待ACK一次所能发送的数据就是4000字节，因此滑动窗口的大小就是4000字节。（四个段）
  - 现在连续发送1001-2000、2001-3000、3001-4000、4001-5000这四个段的时候，不需要等待任何ACK，可以直接进行发送。
  - 当收到对方响应的确认序号为2001时，说明1001-2000这个数据段已经被对方收到了，此时该数据段应该被纳入发送缓冲区当中的第一部分，而由于我们假设对方的窗口大小一直是4000，因此滑动窗口现在可以向右移动，继续发送5001-6000的数据段，以此类推。
  - 滑动窗口越大，则网络的吞吐率越高，同时也说明对方的接收能力很强。



**滑动窗口的本质：**

> 发送方，可以一次性向对方推送的数据的上限，滑动窗口也必须要有上限 == min(对方的接收能力决定，自身拥塞窗口大小的较小值)
>
> 1. 想给对方推送更多的数据。
> 2. 又想要保证对方来的及接收。
>
>  是一个兼顾效率和安全的策略。

![img](https://img-blog.csdnimg.cn/33eaa90663e942348e4e4d0d1b9f511e.png)

![img](https://img-blog.csdnimg.cn/6ce67764b05143079b9c2540ee65ac9b.png)



- **滑动窗口必须向右移吗？**

  >  不一定，因为有可能给对方发的数据，对方ACK应答，因为有可能对方并未取数据，导致接收能力下降，从而win_end不移动，win_start向右移动。

  ![img](https://img-blog.csdnimg.cn/a311ef5811d64e96ab95a499b08b1d84.png)

![img](https://img-blog.csdnimg.cn/3b1fbffafcd4439fa42a99005631b14d.png)

**（仅仅是基于现在的理解，在阻塞控制完善）** 

因此滑动窗口在向右移动的过程中并不一定是整体右移的，因为对方接收能力可能不断在变化，从而滑动窗口也会随之不断变宽或者变窄。



- **如何实现滑动窗口**

  TCP接收和发送缓,冲中区都看作一个字符数组，而滑动窗口实际就可以看作是两个指针限定的一个范围，比如我们用start指向滑动窗口的左侧，end指向的是滑动窗口的右侧，此时在start和end区间范围内的就可以叫做滑动窗口。

  当发送端收到对方的响应时，如果响应当中的确认序号为x，窗口大小为win，此时就可以将start更新为x，而将end更新为start + win

![img](https://img-blog.csdnimg.cn/3df481c805274e5da3a4bce6b25b0298.png)



- **滑动窗口可以为0吗？**

  > 相当于win_start == win_end，是可以。因为发送方一直给对方发数据，接收方上层一直不把数据取走，自然而然的接收能力越来越小，当缓冲区剩余空间为0时，自然而然的滑动窗口可以为0。



- **如果没有收到开始的报文的应答，而是收到中间的？有影响吗？**

>   没有任何影响，因为序号的定义就是：确认序号对应的数字，之前的所有的报文已经全部收到了！告诉对方，下一次发送，就从确认序号指明的序号发送。



- **丢包问题**

当发送端一次发送多个报文数据时，此时的丢包情况也可以分为两种。



**情况一：** 数据包已经抵达，ACK丢包。

![img](https://img-blog.csdnimg.cn/bd62d554744c49788fe163218d9cec4b.png)

在发送端连续发送多个报文数据时，部分ACK丢包并不要紧，此时可以通过后续的ACK进行确认。

比如图中2001-3000和4001-5000的数据包对应的ACK丢失了，但只要发送端收到了最后5001-6000数据包的响应，此时发送端也就知道2001-3000和4001-5000的数据包实际上被接收端收到了的，因为如果接收方没有收到2001-3000和4001-5000的数据包是设置确认序号为6001的，确认序号为6001的含义就是序号为1-6000的字节数据我都收到了，你下一次应该从序号为6001的字节数据开始发送。



**情况二：** 数据包丢了。

![img](https://img-blog.csdnimg.cn/2e633b3e60ec402297388ff6be0fb660.png)

- 当1001-2000的数据包丢失后，发送端会一直收到确认序号为1001的响应报文，就是在提醒发送端“下一次应该从序号为1001的字节数据开始发送”。
- 如果发送端连续收到三次确认序号为1001的响应报文，此时就会将1001-2000的数据包重新进行发送。
- 此时当接收端收到1001-2000的数据包后，就会直接发送确认序号为6001的响应报文，因为2001-6000的数据接收端其实在之前就已经收到了。



#### 快重传

 这种机制被称为： **"高速重发控制"**（也叫 "快重传" ） (看上面)



- **快重传** **VS** **超时重传**

> - 快重传是能够快速进行数据的重发，当发送端连续收到三次相同的应答时就会触发快重传，而不像超时重传一样需要通过设置重传定时器，在固定的时间后才会进行重传。
> - 虽然快重传能够快速判定数据包丢失，但快重传并不能完全取待超时重传，因为有时数据包丢失后可能并没有收到对方三次重复的应答，此时快重传机制就触发不了，而只能进行超时重传。
> - 因此快重传虽然是一个效率上的提升，但超时重传却是所有重传机制的保底策略，也是必不可少的。



- **滑动窗口如果一直向右滑动，会不会出现越界问题？**

> 不会的，因为其是一个**环形结构**（TCP的缓冲区是环状的）！**核心：**根据模运算下标形成的**环状结构**（线性结构模拟环状结构）。



- **滑动窗口中的数据一定都没有被对方收到吗？**

> 滑动窗口当中的数据是可以暂时不用收到对方确认的数据，而不是说滑动窗口当中的数据一定都没有被对方收到，滑动窗口当中可能有一部分数据已经被对方收到了，但可能因为滑动窗口内靠近滑动窗口左侧的一部分数据，在传输过程中出现了丢包等情况，导致后面已经被对方收到的数据得不到响应。

例如图中的1001-2000的数据包如果在传输过程中丢包了，此时虽然2001-5000的数据都被对方收到了，此时对方发来的确认序号也只能是1001，当发送端补发了1001-2000的数据包后，对方发来的确认序号就会变为5001，此时发送缓冲区当中1001-5000的数据也会立马被归置到滑动窗口的左侧。
![img](https://img-blog.csdnimg.cn/bd54d8fe6d2541b18e0ebe5f802ad91d.png)



#### **总结**

  滑动窗口的更新策略就一个要求，只要其收到应答序号是几，就该成几。其不用担心中间数据段的丢失，还是ACK应答丢失，因为只要根据序号的定义即可！

- **滑动窗口是解决效率问题？还是可靠性问题？**

> ​    是解决效率问题的，并不是解决可靠性问题的。对于滑动窗口来讲，其是通过一次限定发送缓冲区的范围，以达到可以向对方一次塞大量的数据，这就是解决效率问题。对于**可靠性问题**也就是配合超时重传。



---

### **拥塞控制**



#### **知识铺垫**

![img](https://img-blog.csdnimg.cn/cd4bbf40c5554f0ca80d1c4295609a4c.png)



  这就是说前述的所有的机制，更多的是主机A如何如何，主机B如何如何。可是在TCP中作为一个数据，不仅仅是在主机上，还要经过网络，所以还要考虑一个总要的问题，网络的健康状态。



- **少量丢包** - 主机的问题 - **重传即可。**
- **大量丢包** - 网络出现问题 (网络拥塞了) - **重传吗？**



 是不是真的拥塞不知道，反正判定为拥塞了，如果不是拥塞是网络瘫痪了，那重传几次不行，还是失败了，最后就直接关闭连接了。如果真的是拥塞了，而软件上只能解决软件上的问题，所以网络拥塞就绝对不能重传了。



- **TCP不仅考虑了通信双端主机的问题，同时也考虑了网络的问题。**

  - 流量控制：考虑的是对端接收缓冲区的接收能力，进而控制发送方发送数据的速度，避免对端接收缓冲区溢出。

  - 滑动窗口：考虑的是发送端不用等待ACK一次所能发送的数据最大量，进而提高发送端发送数据的效率。

  - 拥塞窗口：考虑的是双方通信时网络的问题，如果发送的数据超过了拥塞窗口的大小就可能会引起网络拥塞。

    

    

    > 1. 网络已经拥塞了，再怎么重传没有任何意义，数据照样过不去。
    > 2. 因为丢包是大量丢包，所以重传就会是大量重传，从而加重网络的拥塞。

   



- **如果出现了网络拥塞，如何解决网路拥塞的问题？**

​	      拥塞控制！



#### 概念

虽然TCP有了滑动窗口这个大杀器，能够高效可靠的发送大量的数据，但是如果在刚开始阶段就发送大量的数据，仍然可能引发问题。

因为网络上有很多的计算机，可能当前的网络状态就已经比较拥堵。在不清楚当前网络状态下，贸然发送大量的数据，是很有可能引起雪上加霜的。所以一旦触发了网络拥塞，就会立马触发TCP的拥塞控制算法。

 TCP拥塞控制算法：核心思路在于引入 **慢启动** 机制，先发少量的数据，探探路，摸清当前的网络拥堵状态，再决定按照多大的速度传输数据。

![img](https://img-blog.csdnimg.cn/75a1522626dc4de9ba4e16e6f81ef286.png)

说白了就是，先发送一个数据段，如果没收到确认，那过一会再发一下，如果还是没收到确认，那过会在再发送，依次持续一段，当次序一段时间后还是没有应答，于是就可能不仅仅是网络拥塞了，而是网络瘫痪了，那么主机也只能关闭链接了。如果持续一段收到了，那证明还能用，但是确实阻塞了，然后再发它就会发两个报文如果收到，然后就三个，然后四个以此逐渐增加（探路）。

- 此处引入一个概念程为 **拥塞窗口** **。**
- 发送开始的时候，定义拥塞窗口大小为1。
- 每次收到一个ACK应答，拥塞窗口加1。
- 每次发送数据包的时候，将拥塞窗口和接收端主机反馈的16位窗口大小做比较，取较小的值作为实际发送的窗口。即滑动窗口的大小。



每收到一个ACK应答拥塞窗口的值就加一，此时拥塞窗口就是以指数级别进行增长的，如果先不考虑对方接收数据的能力，那么滑动窗口的大家就只取决于拥塞窗口的大小，此时拥塞窗口的大小变化情况如下：



| **拥塞窗口** | **滑动窗口** |
| ------------ | ------------ |
| 1 = 2^0      | 1            |
| 1+1 = 2^1    | 2            |
| 2+2 = 2 ^2   | 4            |
| 4+4 = 2^3    | 8            |
| ...          | ...          |



- **拥塞窗口：**

> 一台主机同时向另一台主机发送一个大量数据时，可能触发网络拥塞的一个数据。它衡量的是网络一次能够接收来自于我们这一台主机最多的数据上限。
>
>  单机主机一次向网络中发送大量数据时，可能会引发网络阻塞的上限值。
>
>   **即：滑动窗口的大小 = min(阻塞窗口，对方的窗口大小[接收能力])**



但指数级增长是非常快的，因此“慢启动”实际只是初始时比较慢，但越往后增长的越快。如果拥塞窗口的值一直以指数的方式进行增长，此时就可能在短时间内再次导致网络出现拥塞。

- 为了避免短时间内再次导致网络拥塞，因此不能一直让拥塞窗口按指数级的方式进行增长。
- 此时就引入了慢启动的阈值，当拥塞窗口的大小超过这个阈值时，就不再按指数的方式增长，而按线性的方式增长。
- 当TCP刚开始启动的时候，慢启动阈值设置为对方窗口大小的最大值。
- 在每次超时重发的时候，慢启动阈值会变成当前拥塞窗口的一半，同时拥塞窗口的值被重新置为1，如此循环下去。

 如下图：

![img](https://img-blog.csdnimg.cn/8db3d256379941ac907c1ee327307b36.png)

图示说明：

- 指数增长。刚开始进行TCP通信时拥塞窗口的值为1，并不断按指数的方式进行增长。
- 加法增大。慢启动的阈值初始时为对方窗口大小的最大值，图中慢启动阈值的初始值为16，因此当拥塞窗口的值增大到16时就不再按指数形式增长了，而变成了的线性增长。
- 乘法减小。拥塞窗口在线性增长的过程中，在增大到24时如果发生了网络拥塞，此时慢启动的阈值将变为当前拥塞窗口的一半，也就是12，并且拥塞窗口的值被重新设置为1，所以下一次拥塞窗口由指数增长变为线性增长时拥塞窗口的值应该是12。

主机在进行网络通信时，实际就是在不断进行指数增长、加法增大和乘法减小。

> 需要注意的是，不是所有的主机都是同时在进行指数增长、加法增大和乘法减小的。每台主机认为拥塞窗口的大小不一定是一样的，即便是同区域的两台主机在同一时刻认为拥塞窗口的大小也不一定是完全相同的。因此在同一时刻，可能一部分主机正在进行正常通信，而另一部分主机可能已经发生网络拥塞了。

---



- **为什么阻塞之后，前期是指数增长？**

指数前期慢，后期非常快，一旦阻塞：

1. 前期要让网络有一个缓一缓的机会 —— 发送：**少、慢**。

2. 中后期，网络回复之后，尽快恢复通讯的过程 —— 慢慢的发：**可能会影响通讯效率**。

   > - 当TCP开始启动的时候，慢启动阈值等于窗口最大值。
   > - 在每次超时重发的时候，慢启动阈值会变成原来的一半, 同时拥塞窗口置回1。



少量的丢包，我们仅仅是触发超时重传。大量的丢包，我们就认为网络拥塞。当TCP通信开始后，网络吞吐量会逐渐上升。随着网络发生拥堵，吞吐量会立刻下降。拥塞控制，归根结底是TCP协议想尽可能快的把数据传输给对方，但是又要避免给网络造成太大压力的折中方案。

---



#### **总结**

采用**指数 + 线性**增长。

1. 想解决网络阻塞的问题。
2. 尽快恢复双方通信的效率。

**核心：**在于对网络拥塞的**判断**。

1. 少量丢包 － 可以重传。

2. 大量丢包 － 立马判定是网络拥塞了

因为大量丢包无非就三个原因：1、网络阻塞；2、发送太快对方无法接收 / 对方连接断了；3、网络瘫痪；

> 而对于第二个，有对应的[流量控制](https://so.csdn.net/so/search?q=流量控制&spm=1001.2101.3001.7020)并且对端的连接也是健康链接，所以发送放给接收方发数据接收方根本不会出现来不及接受，甚至不接受的问题。

---



### **延迟应答**

> 如果接收数据的主机收到数据后立即进行ACK应答，此时返回的窗口可能比较小。

- 假设对方接收端缓冲区剩余空间大小为1M，对方一次收到500K的数据后，如果立即进行ACK应答，此时返回的窗口就是500K。
- 但实际接收端处理数据的速度很快，10ms之内就将接收缓冲区中500K的数据消费掉了。
- 在这种情况下，接收端处理还远没有达到自己的极限，即使窗口再放大一些，也能处理过来。
- 如果接收端稍微等一会再进行ACK应答，比如等待200ms再应答，那么这时返回的窗口大小就是1M。



需要注意的是，延迟应答的目的不是为了保证可靠性，而是留出一点时间让接收缓冲区中的数据尽可能被上层应用层消费掉，此时在进行ACK响应的时候报告的窗口大小就可以更大，从而增大网络吞吐量，进而提高数据的传输效率。![img](https://img-blog.csdnimg.cn/83cb3017be314719a85bb07a927d67ba.png)



此外，不是所有的数据包都可以延迟应答。

- 数量限制：每个N个包就应答一次。
- 时间限制：超过最大延迟时间就应答一次（这个时间不会导致误超时重传）。

延迟应答具体的数量和超时时间，依操作系统不同也有差异，一般N取2，超时时间取200ms。

---

### **捎带应答**

 在延迟应答的基础上，我们发现，很多情况下，客户端服务器在应用层也是 "一发一收" 的。意味着客户端给服务器说了 "How are you"，服务器也会给客户端回一个 "Fine, thank you"。

那么这个时候ACK就可以搭顺风车，和服务器回应的 "Fine, thank you" 一起回给客户端。将应答 -> ACK -> 报头，搭回复的数据的顺风车，顺便将应答发送端。

![img](https://img-blog.csdnimg.cn/03e72496bfc44741b82a9294f9538a4f.png)

> 捎带应答最直观的角度实际也是发送数据的效率，此时双方通信时就可以不用再发送单纯的确认报文了。

> 此外，由于捎带应答的报文携带了有效数据，因此对方收到该报文后会对其进行响应，当收到这个响应报文时不仅能够确保发送的数据被对方可靠的收到了，同时也能确保捎带的ACK应答也被对方可靠的收到了。

---



## 6. 面向字节流

- 当创建一个TCP的socket时，同时在内核中会创建一个发送缓冲区和一个接收缓冲区。

   

  - 调用write函数就可以将数据写入发送缓冲区中，此时write函数就可以进行返回了，接下来发送缓冲区当中的数据就是由TCP自行进行发送的。
  - 如果发送的字节数太长，TCP会将其拆分成多个数据包发出。如果发送的字节数太短，TCP可能会先将其留在发送缓冲区当中，等到合适的时机再进行发送。
  - 接收数据的时候，数据也是从网卡驱动程序到达内核的接收缓冲区，可以通过调用read函数来读取接收缓冲区当中的数据。
  - 而调用read函数读取接收缓冲区中的数据时，也可以按任意字节数进行读取。



由于缓冲区的存在，TCP程序的读和写不需要一一匹配，例如：

- 写100个字节数据时，可以调用一次write写100字节，也可以调用100次write，每次写一个字节。
- 读100个字节数据时，也完全不需要考虑写的时候是怎么写的，既可以一次read100个字节，也可以一次read一个字节，重复100次。

实际对于TCP来说，它并不关心发送缓冲区当中的是什么数据，在TCP看来这些只是一个个的字节数据，它的任务就是将这些数据准确无误的发送到对方的接收缓冲区当中就行了，而至于如何解释这些数据完全由上层应用来决定，这就叫做面向字节流。

---



## 7 粘包问题



- **什么是粘包**

  - 首先要明确，粘包问题中的“包”，是指的**应用层的数据包**。

  - 在TCP的协议头中，没有如同UDP一样的“报文长度”这样的字段。
  - 站在传输层的角度，TCP是一个一个报文过来的，按照序号排好序放在缓冲区中。
  - 但站在应用层的角度，看到的只是一串连续的字节数据。
  - 那么应用程序看到了这么一连串的字节数据，就不知道从哪个部分开始到哪个部分，是一个完整的应用层数据包。



- **如何解决粘包问题**

  > 要解决粘包问题， 归根结底就是一句话，**明确两个包之间的**边界**！想办法在协议中体现报文和报文之间的边界。**
  >
  > 
  >
  > - 对于定长的包，保证每次都按固定大小读取即可。
  > - 对于变长的包，可以在报头的位置，约定一个包总长度的字段，从而就知道了包的结束位置。比如HTTP报头当中就包含Content-Length属性，表示正文的长度。
  > - 对于变长的包，还可以在包和包之间使用明确的分隔符。因为应用层协议是程序员自己来定的，只要保证分隔符不和正文冲突即可。



- **UDP是否存在粘包问题？**
  - 对于UDP，如果还没有上层交付数据，UDP的报文长度仍然在，同时，UDP是一个一个把数据交付给应用层的，有很明确的数据边界。
  - 站在应用层的角度，使用UDP的时候，要么收到完整的UDP报文，要么不收，不会出现“半个”的情况。

因此UDP是不存在粘包问题的，根本原因就是UDP报头当中的16位UDP长度记录的UDP报文的长度，因此UDP在底层的时候就把报文和报文之间的边界明确了，而TCP存在粘包问题就是因为TCP是面向字节流的，TCP报文之间没有明确的边界。



## 8. TCP异常情况



- **进程终止：**

​	当客户端正常访问服务器时，如果客户端进程突然崩溃了，此时建立好的连接会怎么样？

​	当一个进程退出时，该进程曾经打开的文件描述符都会自动关闭，因此当客户端进程退出时，相当于自动调用了close函数关闭了对应的文件描述符，此时双方操作系统在底层会正常完成四次挥手，然后释放对应的连接资源。

​		也就是说 -> 进程终止会释放文件描述符，仍然可以发送FIN，和正常关闭没有什么区别。



- **机器重启 / 关机**

​	当客户端正常访问服务器时，如果将客户端主机重启，此时建立好的连接会怎么样？

​	当我们选择重启主机时，操作系统会先杀掉所有进程然后再进行关机重启，因此机器重启和进程终止的情况是一样的，此时双方操作系统也会正常完成四次挥手，然后释放对应的连接资源。



- **机器掉电 / 网线断开：**

​	当客户端正常访问服务器时，如果将客户端突然掉线了，此时建立好的连接会怎么样？

​	当客户端掉线后，服务器端在短时间内无法知道客户端掉线了，因此在服务器端会维持与客户端建立的连接，但这个连接也不会一直维持，因为TCP是有保活策略的。

- 服务器会定期客户端客户端的存在状况，检查对方是否在线，如果连续多次都没有收到ACK应答，此时服务器就会关闭这条连接。
- 此外，客户端也可能会定期向服务器“报平安”，如果服务器长时间没有收到客户端的消息，此时服务器也会将对应的连接关闭。

其中服务器定期询问客户端的存在状态的做法，叫做基于保活定时器的一种心跳机制，是由TCP实现的。此外，应用层的某些协议，也有一些类似的检测机制，例如基于长连接的HTTP，也会定期检测对方的存在状态。例如QQ，在QQ断线之后，也会定期尝试重新连接。

>  QQ在发现用户长时间不动用电脑，QQ头像就会变为灰色，就是先将我们的QQ和腾讯的服务端先断开，但是照样保证我们的QQ是登录状态，所以一旦检测到用户回来了（鼠标发生移动），QQ就会自动的迅速的将连接重新建立起来。





## 9. TCP小结



- TCP协议这么复杂就是因为TCP既要保证可靠性，同时又尽可能的提高性能。

  

- 可靠性：

  - 检验和。

  - 序列号。

  - 确认应答。

  - 超时重传。

  - 连接管理。

  - 流量控制。

  - 拥塞控制。

    

- 提高性能：

  - 滑动窗口。

  - 快速重传。

  - 延迟应答。

  - 捎带应答。

需要注意的是，TCP的这些机制有些能够通过TCP报头体现出来的，但还有一些是通过代码逻辑体现出来的。



- **TCP定时器**

  > 此外，TCP当中还设置了各种定时器。

  - 重传定时器：为了控制丢失的报文段或丢弃的报文段，也就是对报文段确认的等待时间。
  - 坚持定时器：专门为对方零窗口通知而设立的，也就是向对方发送窗口探测的时间间隔。
  - 保活定时器：为了检查空闲连接的存在状态，也就是向对方发送探查报文的时间间隔。
  - TIME_WAIT定时器：双方在四次挥手后，主动断开连接的一方需要等待的时长。
    



- **理解传输控制协议**

> TCP的各种机制实际都没有谈及数据真正的发送，这些都叫做传输数据的策略。TCP协议是在网络数据传输当中做决策的，它提供的是理论支持，比如TCP要求当发出的报文在一段时间内收不到ACK应答就应该进行超时重传，而数据真正的发送实际是由底层的IP和MAC帧完成的。

> TCP做决策和IP+MAC做执行，我们将它们统称为通信细节，它们最终的目的就是为了将数据传输到对端主机。而传输数据的目的是什么则是由应用层决定的。因此应用层决定的是通信的意义，而传输层及其往下的各层决定的是通信的方式。



---

## 10. 基于TCP的应用层协议

- HTTP（超文本传输协议）。
- HTTPS（安全数据传输协议）。
- SSH（安全外壳协议）。
- Telnet（远程终端协议）。
- FTP（文件传输协议）。
- SMTP（电子邮件传输协议）。

当然，也包括你自己写TCP程序时自定义的应用层协议。



- **谈谈云服务器**

  SSH也就是Xshell的底层协议，我们使用Xshell时实际就是使用Xshell的ssh客户端连接我们的云服务器。

​		我们在使用Xshell时，可以通过`ssh 用户名@主机名（IP地址）`方式连接云服务器。实际就是因为我们的云服务器当中存在sshd这样的服务。

![img](https://img-blog.csdnimg.cn/78b7d93c9d9d45b4ae2d53626070c750.png)

这实际就是ssh服务的服务器端，我们使用的`ssh 用户名@主机名（IP地址）`命令当中的ssh实际是ssh的客户端，因此我们连接云服务器时本质是在用ssh的客户端连接ssh的服务器。

使用`netstat`命令可以看到对应的ssh服务。

![img](https://img-blog.csdnimg.cn/f551fc6acb744d0780de350e183ce0f1.png)

我们在云服务器上敲出的各种命令，最终会通过网络套接字的方式发送给服务器，由服务器来对我们的命令进行各种解释，进而执行对应的动作。

---

